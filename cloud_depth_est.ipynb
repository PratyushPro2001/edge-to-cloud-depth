{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLJy6gAcvwb-"
      },
      "outputs": [],
      "source": [
        "!pip install fastapi uvicorn nest-asyncio python-multipart timm opencv-python pyngrok\n",
        "\n",
        "!git clone https://github.com/isl-org/MiDaS.git\n",
        "\n",
        "!wget https://huggingface.co/Intel/dpt-large/resolve/main/dpt_large-midas-2f21e586.pt -O /content/dpt_large-midas.pt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/MiDaS')\n"
      ],
      "metadata": {
        "id": "zltOFOczy6DT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from torchvision.transforms import Compose\n",
        "import nest_asyncio\n",
        "import uvicorn\n",
        "from fastapi import FastAPI, File, UploadFile\n",
        "from fastapi.responses import Response\n",
        "\n",
        "# Setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load MiDaS model\n",
        "model_type = \"MiDaS_small\"  # options: \"DPT_Large\", \"DPT_Hybrid\", \"MiDaS_small\"\n",
        "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type)\n",
        "midas.to(device)\n",
        "midas.eval()\n",
        "\n",
        "# Load transforms\n",
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
        "transform = midas_transforms.dpt_transform"
      ],
      "metadata": {
        "id": "loQjW_0QzCJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app = FastAPI()\n",
        "\n",
        "@app.post(\"/predict\")\n",
        "async def predict_depth(image: UploadFile = File(...)):\n",
        "    contents = await image.read()\n",
        "    img_np = np.frombuffer(contents, np.uint8)\n",
        "    img = cv2.imdecode(img_np, cv2.IMREAD_COLOR)\n",
        "\n",
        "    # Preprocess\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    input_tensor = transform(img_rgb).to(device)\n",
        "\n",
        "    # Predict\n",
        "    with torch.no_grad():\n",
        "        prediction = midas(input_tensor)\n",
        "        prediction = torch.nn.functional.interpolate(\n",
        "            prediction.unsqueeze(1),\n",
        "            size=img.shape[:2],\n",
        "            mode=\"bicubic\",\n",
        "            align_corners=False\n",
        "        ).squeeze()\n",
        "\n",
        "    # Postprocess\n",
        "    depth_map = prediction.cpu().numpy()\n",
        "    depth_map = cv2.normalize(depth_map, None, 0, 255, cv2.NORM_MINMAX)\n",
        "    depth_map = depth_map.astype(np.uint8)\n",
        "    depth_color = cv2.applyColorMap(depth_map, cv2.COLORMAP_MAGMA)\n",
        "\n",
        "    _, encoded_img = cv2.imencode('.jpg', depth_color)\n",
        "    return Response(content=encoded_img.tobytes(), media_type=\"image/jpeg\")\n",
        "\n",
        "# Allow FastAPI to run in Colab\n",
        "nest_asyncio.apply()\n"
      ],
      "metadata": {
        "id": "-llzeqGG1bH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken <<paste your ngrok token here>>\n"
      ],
      "metadata": {
        "id": "2q9fBY2mZRD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect(7860)\n",
        "print(\"ðŸ”— Public URL:\", public_url)\n"
      ],
      "metadata": {
        "id": "IhMQ0axw2cZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uvicorn.run(app, host=\"0.0.0.0\", port=7860)\n"
      ],
      "metadata": {
        "id": "-O6omHlKzPJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill -f ngrok\n",
        "\n"
      ],
      "metadata": {
        "id": "_Pn-5mP9zRie"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}